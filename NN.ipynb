{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parthapratimkalita/ELOBSE/blob/master/NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7wbP6XiboZJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ee7f617-dc30-4921-e480-b0c56435abbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np #importing the numpy array as np\n",
        "\n",
        "x = np.random.randint(0, 2, size=6) #generating a random array 'x' where lowest element can be one and highest could be 2-1.\n",
        "\n",
        "t = [] #intializing an array t\n",
        "\n",
        "for i in range(len(x)):\n",
        "  m = x[i]**3 - x[i]**2\n",
        "  t.append(m)\n",
        "\n",
        "t = np.array(t)\n",
        "\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2wTshi_kS0sA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Layers:\n",
        "\n",
        "  def __init__(self, n_units, input_units):\n",
        "\n",
        "    self.n_units = n_units\n",
        "    self.input_units = input_units\n",
        "    \n",
        "\n",
        "    self.weights = np.random.randint(1,4, size=(self.input_units, self.n_units))\n",
        "    self.biases = np.zeros(shape=(1, self.n_units), dtype= 'i')\n",
        "\n",
        "\n",
        "  def Relu(self,m):\n",
        "\n",
        "    shape = m.shape\n",
        "    comp = np.zeros(shape=(1, shape[1]), dtype= 'i')\n",
        "    return np.maximum(m,comp)\n",
        "\n",
        "  def forward_step(self, input_values):\n",
        "\n",
        "    self.input_values = input_values\n",
        "    self.input_values = np.asarray(self.input_values).reshape(1,self.input_units)\n",
        "\n",
        "    self.sum = np.dot(self.input_values, self.weights) \n",
        "\n",
        " \n",
        "    self.sum = self.sum + self.biases\n",
        "\n",
        "    self.output = self.Relu(self.sum)\n",
        "    return self.output\n",
        "\n",
        "\n",
        "  def derivative_out_wrt_act(self, out1):\n",
        "\n",
        "      shape = out1.shape\n",
        "\n",
        "      for i in range(shape[1]):\n",
        "          if out1[0][i] <= 0:\n",
        "              out1[0][i] = 0\n",
        "          else:\n",
        "              out1[0][i] = 1\n",
        "\n",
        "      return out1\n",
        "\n",
        "\n",
        "  def loss(self, ta1):\n",
        "\n",
        "    ta1 = np.array(ta1).reshape(1, len(ta1))\n",
        "\n",
        "    #print(ta1)\n",
        "    #print(self.output)\n",
        "    derv_loss_wrt_out = self.output - ta1\n",
        "    return derv_loss_wrt_out\n",
        "\n",
        "  def hidden_layer_loss(self, loss1, weights):\n",
        "\n",
        "    hid_loss = np.dot( loss1, np.transpose(weights))\n",
        "    return hid_loss\n",
        "\n",
        "\n",
        "  def backward_step(self, lear_rate, loss, prev):\n",
        "      \n",
        "\n",
        "      #print(\"@@@@\")\n",
        "\n",
        "      derv_loss_wrt_out = loss\n",
        "      #print(derv_loss_wrt_out)\n",
        "      derv_out_wrt_act  = self.derivative_out_wrt_act(self.sum)\n",
        "      #print(derv_out_wrt_act)\n",
        "      derv_input_wrt_wei = self.input_values\n",
        "      #print(derv_input_wrt_wei)\n",
        "\n",
        "      right = derv_loss_wrt_out * derv_out_wrt_act  * prev\n",
        "\n",
        "      loss_wrt_wei = np.dot(np.transpose(derv_input_wrt_wei),  right)\n",
        "      \n",
        "      self.weights = self.weights - lear_rate * loss_wrt_wei\n",
        "\n",
        "      return [right, self.weights]\n",
        "\n",
        "    \n",
        "      #return self.output\n",
        "\n",
        "\n",
        "# Multi layer perceptron class with two layers\n",
        "\n",
        "class MLP(Layers):\n",
        "\n",
        "  Lar_h = Layers(10,1)\n",
        "  Lar_out = Layers(1,10) \n",
        "\n",
        "\n",
        "#loss calculation of the network\n",
        "  def end_loss(y, t):\n",
        "      sq = (y-t)*(y-t)\n",
        "      los = 0.5 * sq\n",
        "\n",
        "      return los\n",
        "\n",
        "  for i in range(10):\n",
        "\n",
        "      for j in range(6):\n",
        "\n",
        "# Implementing feedforward propagation on hidden layer\n",
        "        out = Lar_h.forward_step([x[j]])\n",
        "\n",
        "# Implementing feed forward propagation on output layer\n",
        "        out1 = Lar_out.forward_step(out[0])\n",
        "\n",
        "\n",
        "\n",
        "# Backpropagation phase\n",
        "\n",
        "        # Calculating the error at output nodes\n",
        "        loss = Lar_out.loss([t[j]])\n",
        "\n",
        "        back_derv_1 = Lar_out.backward_step(0.5, loss, 1)\n",
        "\n",
        "        \n",
        "        #Calculating the error at the hidden nodes\n",
        "        loss = Lar_h.hidden_layer_loss(loss, back_derv_1[1])\n",
        "\n",
        "        back_derv_2 = Lar_h.backward_step(0.5, loss, back_derv_1[0] )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHiW9f4MY5NyEDpAbWNnNB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}